{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Project: Refining the Art of Sentiment Analysis at ModaMetric\n",
    "\n",
    "Welcome to Week 2! The ModaMetric team is still buzzing from the achievements of last week. You've shown them the power of Metaflow and the potential of machine learning. However, there's more to explore, more to refine.\n",
    "\n",
    "Once again, weâ€™ll delve into the [Women's Ecommerce Clothing Reviews Dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews), the dataset that helped us unlock valuable insights for ModaMetric. Your mission is to further refine the sentiment analysis process, enabling ModaMetric to better understand the sentiments embedded in the customer reviews.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Project Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parallel_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile parallel_flow.py\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact\n",
    "import numpy as np\n",
    "\n",
    "def labeling_function(row):\n",
    "    \"\"\"\n",
    "    Label a provided row based on the \"rating\" column value.\n",
    "    \n",
    "    Parameters:\n",
    "    - row (pd.Series): A row from a DataFrame with a \"rating\" key.\n",
    "    \n",
    "    Returns:\n",
    "    - int: 1 if rating is 4 or 5 (indicating a positive review), otherwise 0.\n",
    "    \"\"\"\n",
    "    return 1 if row[\"rating\"] in [4, 5] else 0\n",
    "\n",
    "class ParallelFlow(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    seed = Parameter(\"random_seed\", default=42)\n",
    "    data = IncludeFile(\"data\", default=\"../data/Womens Clothing E-Commerce Reviews.csv\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Load and preprocess the dataset\n",
    "        df = pd.read_csv(io.StringIO(self.data))\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df[\"review_text\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # Split data for training and validation\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, \n",
    "                                                     test_size=self.split_size,\n",
    "                                                     random_state=self.seed)\n",
    "        self.next(self.baseline, self.make_grid)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        from sklearn.dummy import DummyClassifier\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        # Train and score the baseline model\n",
    "        self.dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "        self.dummy_model.fit(self.traindf[\"review\"], self.traindf[\"label\"])\n",
    "        self.probas = self.dummy_model.predict_proba(self.valdf[\"review\"])[:, 1]\n",
    "        self.preds = self.dummy_model.predict(self.valdf[\"review\"])\n",
    "        self.base_acc = accuracy_score(self.valdf[\"label\"], self.preds)\n",
    "        self.base_rocauc = roc_auc_score(self.valdf[\"label\"], self.probas)\n",
    "\n",
    "        self.next(self.final_join)\n",
    "\n",
    "    @step\n",
    "    def make_grid(self):\n",
    "        from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "        param_values = {'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "        self.grid_points = list(ParameterGrid(param_values))\n",
    "\n",
    "        # evaluate each in cross product of ParameterGrid.\n",
    "        self.next(self.tfidf_lr_text_model, \n",
    "                  foreach='grid_points')\n",
    "\n",
    "    @step\n",
    "    def tfidf_lr_text_model(self):\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        # Get the current grid point\n",
    "        current_grid_point = self.input\n",
    "\n",
    "        # Tokenization using the ngram_range from the current grid point\n",
    "        vectorizer = TfidfVectorizer(ngram_range=current_grid_point['tfidfvectorizer__ngram_range'])\n",
    "\n",
    "        # Estimator\n",
    "        estimator = LogisticRegression(max_iter=1_000)\n",
    "\n",
    "        # Model\n",
    "        self.lr_text_model = make_pipeline(vectorizer, estimator)\n",
    "\n",
    "        # Score via 5-fold Cross-Validation\n",
    "        self.model_scores = cross_val_score(self.lr_text_model,\n",
    "                                            self.traindf[\"review\"],\n",
    "                                            self.traindf[\"label\"],\n",
    "                                            scoring=\"roc_auc\",\n",
    "                                            cv=5)\n",
    "\n",
    "        self.lr_text_roc_auc = np.mean(self.model_scores)\n",
    "        self.lr_text_model.fit(self.traindf[\"review\"], self.traindf[\"label\"])\n",
    "\n",
    "        # Storing the model, parameters, oof data and score\n",
    "        self.current_grid_point = current_grid_point\n",
    "        self.current_model = self.lr_text_model\n",
    "        self.current_score = self.lr_text_roc_auc\n",
    "        self.oof_data = self.valdf\n",
    "\n",
    "\n",
    "        self.next(self.tfidf_join)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def tfidf_join(self, inputs):\n",
    "\n",
    "        # Gather results from each tfidf_lr_text_model branch.\n",
    "        self.lr_text_rocauc = np.max([inp.lr_text_roc_auc for inp in inputs])\n",
    "\n",
    "        # Find the output with the highest score from the parallel branches\n",
    "        best_input = max(inputs, key=lambda inp: inp.current_score)\n",
    "        \n",
    "        # Retrieve and store the best model, its parameters, and its score\n",
    "        self.best_model = best_input.current_model\n",
    "        self.best_parameters = best_input.current_grid_point\n",
    "        \n",
    "        self.oof_data = inputs.tfidf_lr_text_model.oof_data\n",
    "        self.next(self.final_join)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def final_join(self, inputs):\n",
    "        self.base_rocauc = inputs.baseline.base_rocauc\n",
    "        self.lr_text_rocauc = inputs.tfidf_join.lr_text_rocauc\n",
    "        self.best_model = inputs.tfidf_join.best_model\n",
    "        self.best_model_parameters = inputs.tfidf_join.best_parameters\n",
    "        self.oof_data = inputs.tfidf_join.oof_data\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def end(self):\n",
    "        from metaflow import Flow, current\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        # Is the model better than a baseline?\n",
    "        self.beats_baseline = self.lr_text_rocauc > self.base_rocauc\n",
    "\n",
    "        # Smoke testing\n",
    "        _smoke_test_reviews = [\"Hate it. Horrible shoes\",\n",
    "                               \"Beautiful shoes. Loved it\",\n",
    "                              ]\n",
    "\n",
    "        _smoke_test_preds = self.best_model.predict_proba(_smoke_test_reviews)[:,1]\n",
    "        print(_smoke_test_preds) \n",
    "        negative_review = _smoke_test_preds[0] \n",
    "        positive_review = _smoke_test_preds[1] \n",
    "        self.passed_smoke_test = positive_review > negative_review\n",
    "\n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            margin = self.lr_text_rocauc - self.base_rocauc\n",
    "            print(\"Model passed the smoke test\")\n",
    "            print(f\"The model beats the baseline by {margin:0.2f}\")\n",
    "            print(f\"Model 5-fold CV ROC_AUC: {self.lr_text_rocauc:0.2f}\")\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('Deployment_candidate')\n",
    "        else:\n",
    "            print(\"Review this model. Have not passed the minimal tests.\")\n",
    "        \n",
    "        # Out of fold rocauc\n",
    "        oof_preds = self.best_model.predict_proba(self.oof_data[\"review\"])[:,1]\n",
    "        self.oof_rocauc = roc_auc_score(self.oof_data[\"label\"],oof_preds)\n",
    "        print(f\"Out of Fold Model ROC_AUC:{self.oof_rocauc:0.2f}\") \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ParallelFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.7.2+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mParallelFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mIncluding file ../data/Womens Clothing E-Commerce Reviews.csv of size 8MB \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:17.543 \u001b[0m\u001b[1mWorkflow starting (run-id 95), see it in the UI at https://ui-pw-1668674295.outerbounds.dev/ParallelFlow/95\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:17.792 \u001b[0m\u001b[32m[95/start/509 (pid 2402)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:25.101 \u001b[0m\u001b[32m[95/start/509 (pid 2402)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:25.499 \u001b[0m\u001b[32m[95/baseline/510 (pid 2493)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:25.678 \u001b[0m\u001b[32m[95/make_grid/511 (pid 2496)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:29.986 \u001b[0m\u001b[32m[95/make_grid/511 (pid 2496)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:29.986 \u001b[0m\u001b[32m[95/make_grid/511 (pid 2496)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:30.344 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/512 (pid 2595)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:30.524 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/513 (pid 2598)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:30.885 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/514 (pid 2617)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:42:33.468 \u001b[0m\u001b[32m[95/baseline/510 (pid 2493)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:44:20.366 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/512 (pid 2595)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:46:22.148 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/513 (pid 2598)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:47:17.769 \u001b[0m\u001b[1m1 task is running: tfidf_lr_text_model (1 running; 2 done).\u001b[0m\n",
      "\u001b[35m2023-10-29 22:47:17.769 \u001b[0m\u001b[1mNo tasks are waiting in the queue.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:47:17.769 \u001b[0m\u001b[1m3 steps have not started: tfidf_join, final_join, end.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:12.012 \u001b[0m\u001b[32m[95/tfidf_lr_text_model/514 (pid 2617)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:12.391 \u001b[0m\u001b[32m[95/tfidf_join/515 (pid 2908)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:19.647 \u001b[0m\u001b[32m[95/tfidf_join/515 (pid 2908)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:20.086 \u001b[0m\u001b[32m[95/final_join/516 (pid 2986)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:26.714 \u001b[0m\u001b[32m[95/final_join/516 (pid 2986)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:27.169 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:30.119 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[22m[0.59302237 0.8952845 ]\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:31.131 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[22mModel passed the smoke test\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:31.132 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[22mThe model beats the baseline by 0.44\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:31.132 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[22mModel 5-fold CV ROC_AUC: 0.94\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:31.132 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[22mOut of Fold Model ROC_AUC:0.95\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:37.772 \u001b[0m\u001b[32m[95/end/517 (pid 3066)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 22:48:38.089 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-1668674295.outerbounds.dev/ParallelFlow/95\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python parallel_flow.py run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "\n",
    "def get_latest_successful_run(flow_nm, tag):\n",
    "    \"Gets the latest successful run for a flow with a specific tag.\"\n",
    "    for r in Flow(flow_nm).runs(tag):\n",
    "        if r.successful: return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last sucessful model flow\n",
    "run = get_latest_successful_run('ParallelFlow', 'Deployment_candidate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run.data.best_model\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13365</th>\n",
       "      <td>This sweater is so beautiful on. it is thick m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19834</th>\n",
       "      <td>This piece is almost what i want... i tried on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18722</th>\n",
       "      <td>Really like this blouse but am returning for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10635</th>\n",
       "      <td>These are the perfect light weight relaxing su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>These look nothing like the picture! they are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "13365  This sweater is so beautiful on. it is thick m...      1\n",
       "19834  This piece is almost what i want... i tried on...      1\n",
       "18722  Really like this blouse but am returning for a...      1\n",
       "10635  These are the perfect light weight relaxing su...      1\n",
       "7348   These look nothing like the picture! they are ...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unseen Data\n",
    "oof_data = run.data.oof_data\n",
    "oof_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97345776, 0.70724746, 0.53964221, ..., 0.40992763, 0.96232039,\n",
       "       0.8511883 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores of being a positive review\n",
    "preds = model.predict_proba(oof_data[\"review\"])[:,1]\n",
    "preds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
