{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Project: Refining the Art of Sentiment Analysis at ModaMetric\n",
    "\n",
    "Welcome to Week 2! The ModaMetric team is still buzzing from the achievements of last week. You've shown them the power of Metaflow and the potential of machine learning. However, there's more to explore, more to refine.\n",
    "\n",
    "Once again, weâ€™ll delve into the [Women's Ecommerce Clothing Reviews Dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews), the dataset that helped us unlock valuable insights for ModaMetric. Your mission is to further refine the sentiment analysis process, enabling ModaMetric to better understand the sentiments embedded in the customer reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# You can style your plots here, but it is not part of the project.\n",
    "YELLOW = \"#FFBC00\"\n",
    "GREEN = \"#37795D\"\n",
    "PURPLE = \"#5460C0\"\n",
    "BACKGROUND = \"#F4EBE6\"\n",
    "colors = [GREEN, PURPLE]\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.facecolor\": BACKGROUND,\n",
    "    \"figure.facecolor\": BACKGROUND,\n",
    "    \"figure.figsize\": (8, 8),\n",
    "}\n",
    "sns_palette = sns.color_palette(colors, len(colors))\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parallel_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile parallel_flow.py\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact\n",
    "import numpy as np\n",
    "\n",
    "def labeling_function(row):\n",
    "    \"\"\"\n",
    "    Label a provided row based on the \"rating\" column value.\n",
    "    \n",
    "    Parameters:\n",
    "    - row (pd.Series): A row from a DataFrame with a \"rating\" key.\n",
    "    \n",
    "    Returns:\n",
    "    - int: 1 if rating is 4 or 5 (indicating a positive review), otherwise 0.\n",
    "    \"\"\"\n",
    "    return 1 if row[\"rating\"] in [4, 5] else 0\n",
    "\n",
    "class ParallelFlow(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    seed = Parameter(\"random_seed\", default=42)\n",
    "    data = IncludeFile(\"data\", default=\"../data/Womens Clothing E-Commerce Reviews.csv\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Load and preprocess the dataset\n",
    "        df = pd.read_csv(io.StringIO(self.data))\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df[\"review_text\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # Split data for training and validation\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, \n",
    "                                                     test_size=self.split_size,\n",
    "                                                     random_state=self.seed)\n",
    "        self.next(self.baseline, self.make_grid)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        from sklearn.dummy import DummyClassifier\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        # Train and score the baseline model\n",
    "        self.dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "        self.dummy_model.fit(self.traindf[\"review\"], self.traindf[\"label\"])\n",
    "        self.probas = self.dummy_model.predict_proba(self.valdf[\"review\"])[:, 1]\n",
    "        self.preds = self.dummy_model.predict(self.valdf[\"review\"])\n",
    "        self.base_acc = accuracy_score(self.valdf[\"label\"], self.preds)\n",
    "        self.base_rocauc = roc_auc_score(self.valdf[\"label\"], self.probas)\n",
    "\n",
    "        self.next(self.final_join)\n",
    "\n",
    "    @step\n",
    "    def make_grid(self):\n",
    "        from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "        param_values = {'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "        self.grid_points = list(ParameterGrid(param_values))\n",
    "\n",
    "        # evaluate each in cross product of ParameterGrid.\n",
    "        self.next(self.tfidf_lr_text_model, \n",
    "                  foreach='grid_points')\n",
    "\n",
    "    @step\n",
    "    def tfidf_lr_text_model(self):\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        # Get the current grid point\n",
    "        current_grid_point = self.input\n",
    "\n",
    "        # Tokenization using the ngram_range from the current grid point\n",
    "        vectorizer = TfidfVectorizer(ngram_range=current_grid_point['tfidfvectorizer__ngram_range'])\n",
    "\n",
    "        # Estimator\n",
    "        estimator = LogisticRegression(max_iter=1_000)\n",
    "\n",
    "        # Model\n",
    "        self.lr_text_model = make_pipeline(vectorizer, estimator)\n",
    "\n",
    "        # Score via 5-fold Cross-Validation\n",
    "        self.model_scores = cross_val_score(self.lr_text_model,\n",
    "                                            self.traindf[\"review\"],\n",
    "                                            self.traindf[\"label\"],\n",
    "                                            scoring=\"roc_auc\",\n",
    "                                            cv=5)\n",
    "\n",
    "        self.lr_text_roc_auc = np.mean(self.model_scores)\n",
    "        self.lr_text_model.fit(self.traindf[\"review\"], self.traindf[\"label\"])\n",
    "\n",
    "        # Storing the model, parameters, and score\n",
    "        self.current_grid_point = current_grid_point\n",
    "        self.current_model = self.lr_text_model\n",
    "        self.current_score = self.lr_text_roc_auc\n",
    "\n",
    "\n",
    "        self.next(self.tfidf_join)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def tfidf_join(self, inputs):\n",
    "        # Gather results from each tfidf_lr_text_model branch.\n",
    "        self.lr_text_rocauc = np.max([inp.lr_text_roc_auc for inp in inputs])\n",
    "\n",
    "        # Find the output with the highest score from the parallel branches\n",
    "        best_input = max(inputs, key=lambda inp: inp.current_score)\n",
    "        \n",
    "        # Retrieve and store the best model, its parameters, and its score\n",
    "        self.best_model = best_input.current_model\n",
    "        self.best_parameters = best_input.current_grid_point\n",
    "        \n",
    "        self.next(self.final_join)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def final_join(self, inputs):\n",
    "        self.base_rocauc = inputs.baseline.base_rocauc\n",
    "        self.lr_text_rocauc = inputs.tfidf_join.lr_text_rocauc\n",
    "        self.best_model = inputs.tfidf_join.best_model\n",
    "        self.best_model_parameters = inputs.tfidf_join.best_parameters\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def end(self):\n",
    "        from metaflow import Flow, current\n",
    "\n",
    "        # Is the model better than a baseline?\n",
    "        self.beats_baseline = self.lr_text_rocauc > self.base_rocauc\n",
    "\n",
    "        # Smoke testing\n",
    "        _smoke_test_reviews = [\"Hate it. Horrible shoes\",\n",
    "                               \"Beautiful shoes. Loved it\",\n",
    "                              ]\n",
    "\n",
    "        _smoke_test_preds = self.best_model.predict_proba(_smoke_test_reviews)[:,1]\n",
    "        print(_smoke_test_preds) \n",
    "        negative_review = _smoke_test_preds[0] \n",
    "        positive_review = _smoke_test_preds[1] \n",
    "        self.passed_smoke_test = positive_review > negative_review\n",
    "\n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            margin = self.lr_text_rocauc - self.base_rocauc\n",
    "            print(\"Model passed the smoke test\")\n",
    "            print(f\"The model beats the baseline by {margin:0.2f}\")\n",
    "            print(f\"Model 5-fold CV ROC_AUC: {self.lr_text_rocauc:0.2f}\")\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('Deployment_candidate')\n",
    "        else:\n",
    "            print(\"Review this model. Have not passed the minimal tests.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ParallelFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.7.2+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mParallelFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mIncluding file ../data/Womens Clothing E-Commerce Reviews.csv of size 8MB \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:10.323 \u001b[0m\u001b[1mWorkflow starting (run-id 90), see it in the UI at https://ui-pw-1668674295.outerbounds.dev/ParallelFlow/90\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:10.592 \u001b[0m\u001b[32m[90/start/463 (pid 30015)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:17.826 \u001b[0m\u001b[32m[90/start/463 (pid 30015)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:18.210 \u001b[0m\u001b[32m[90/baseline/464 (pid 30112)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:18.430 \u001b[0m\u001b[32m[90/make_grid/465 (pid 30115)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:22.703 \u001b[0m\u001b[32m[90/make_grid/465 (pid 30115)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:22.703 \u001b[0m\u001b[32m[90/make_grid/465 (pid 30115)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:23.118 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/466 (pid 30218)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:23.268 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/467 (pid 30221)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:23.625 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/468 (pid 30240)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:26:26.397 \u001b[0m\u001b[32m[90/baseline/464 (pid 30112)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:28:14.666 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/466 (pid 30218)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:30:10.822 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/467 (pid 30221)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:31:10.466 \u001b[0m\u001b[1m1 task is running: tfidf_lr_text_model (1 running; 2 done).\u001b[0m\n",
      "\u001b[35m2023-10-29 21:31:10.466 \u001b[0m\u001b[1mNo tasks are waiting in the queue.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:31:10.466 \u001b[0m\u001b[1m3 steps have not started: tfidf_join, final_join, end.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:31:57.512 \u001b[0m\u001b[32m[90/tfidf_lr_text_model/468 (pid 30240)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:31:57.951 \u001b[0m\u001b[32m[90/tfidf_join/469 (pid 30538)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:04.526 \u001b[0m\u001b[32m[90/tfidf_join/469 (pid 30538)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:04.897 \u001b[0m\u001b[32m[90/final_join/470 (pid 30615)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:11.025 \u001b[0m\u001b[32m[90/final_join/470 (pid 30615)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:11.579 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:14.498 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[22m[0.59302237 0.8952845 ]\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:20.551 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[22mModel passed the smoke test\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:20.551 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[22mThe model beats the baseline by 0.44\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:20.551 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[22mModel 5-fold CV ROC_AUC: 0.94\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:20.813 \u001b[0m\u001b[32m[90/end/471 (pid 30695)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 21:32:20.952 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-1668674295.outerbounds.dev/ParallelFlow/90\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python parallel_flow.py run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
